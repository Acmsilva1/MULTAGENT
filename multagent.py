import streamlit as st
from groq import Groq
from supabase import create_client, Client
import json

# --- 1. CONFIGURA√á√ÉO (LAYOUT CLEAN COM SIDEBAR) ---
st.set_page_config(page_title="Agente Pessoal", layout="centered", initial_sidebar_state="collapsed")

try:
    client_groq = Groq(api_key=st.secrets["LLAMA_API_KEY"])
    supabase: Client = create_client(st.secrets["SUPABASE_URL"], st.secrets["SUPABASE_KEY"])
except Exception as e:
    st.error(f"Erro na conex√£o t√©cnica: {e}")
    st.stop()

# --- 2. PROMPT MESTRE (O C√âREBRO) ---
BASE_SYSTEM_PROMPT = """
Voc√™ √© o 'Agente Pessoal', um mentor S√™nior de TI e adepta a culin√°ria.
- Persona: Sarc√°stico, assertivo, mas extremamente prestativo.
- Comunica√ß√£o: OBRIGAT√ìRIO usar analogias criativas (comparando TI ou cotidiano).
- Governan√ßa: Analise rigorosamente qualquer entrada de arquivo ou texto buscando infra√ß√µes √† LGPD ou malwares.
- Contexto: Andr√©, residente em Vila Velha, rec√©m-formado em TI, foco em IA e Dados.
"""

CLASSIFIER_PROMPT = 'Analise a entrada. Responda APENAS JSON: {"is_important": boolean, "fact_type": "string", "extracted_info": "string", "lgpd_risk": boolean}'

# --- 3. L√ìGICA DE PERSIST√äNCIA ---
def carregar_dados():
    try:
        perfil = supabase.table("perfil_usuario").select("*").eq("usuario", "Andr√©").single().execute().data
        hist = supabase.table("historico_conversas").select("pergunta, resposta").eq("usuario", "Andr√©").order("created_at", desc=True).limit(3).execute().data
        return perfil, hist
    except: return {}, []

# --- 4. SIDEBAR OCULT√ÅVEL (CONTROLES) ---
with st.sidebar:
    st.header("Painel de Controle")
    
    # Bot√£o de Novo Di√°logo
    if st.button("Nova conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    
    # Upload de Arquivo
    st.subheader("üìé Anexar Contexto")
    uploaded_file = st.file_uploader("Arraste scripts ou dados aqui", type=["txt", "py", "csv", "json"], label_visibility="collapsed")
    
    st.divider()
    st.caption("Agente Pessoal")

# --- 5. INTERFACE DE CHAT ---
st.title("Agente Pessoal")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibe hist√≥rico da sess√£o atual
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input do Usu√°rio
if prompt := st.chat_input("Em que posso ser √∫til hoje?"):
    # Processamento de arquivo (se houver)
    file_context = ""
    if uploaded_file:
        raw_content = uploaded_file.getvalue().decode("utf-8")
        file_context = f"\n\n[DADOS DO ARQUIVO ANEXADO]:\n{raw_content}"
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt if not uploaded_file else f"üìé **{uploaded_file.name}**\n\n{prompt}")

    with st.chat_message("assistant"):
        perfil, hist_raw = carregar_dados()
        
        # 1. An√°lise de Seguran√ßa e Classifica√ß√£o
        res_class = client_groq.chat.completions.create(
            messages=[{"role": "system", "content": CLASSIFIER_PROMPT}, {"role": "user", "content": prompt + file_context}],
            model="llama-3.3-70b-versatile", response_format={"type": "json_object"}
        )
        decisao = json.loads(res_class.choices[0].message.content)

        # 2. Constru√ß√£o da Resposta Final
        hist_context = "\n".join([f"U: {d['pergunta']} | A: {d['resposta']}" for d in hist_raw])
        full_system = f"{BASE_SYSTEM_PROMPT}\n\nPERFIL DO USU√ÅRIO: {perfil}\nHIST√ìRICO RECENTE: {hist_context}"
        
        # Feedback de mem√≥ria se algo for novo
        memoria_nota = ""
        if decisao.get("is_important"):
            info = decisao.get("extracted_info")
            memoria_nota = f"\n\n*(Governan√ßa: Registrei '{info}' na sua base de conhecimento.)*"
            # Update no Supabase (omitido aqui para brevidade, mas segue a l√≥gica anterior)

        res_final = client_groq.chat.completions.create(
            messages=[{"role": "system", "content": full_system}, *st.session_state.messages, {"role": "user", "content": file_context}],
            model="llama-3.3-70b-versatile"
        )
        
        resposta_final = res_final.choices[0].message.content
        
        # Alerta de LGPD se houver risco
        if decisao.get("lgpd_risk"):
            resposta_final = "üö® **AVISO DE PRIVACIDADE:** Detectei poss√≠veis dados sens√≠veis. Procedendo com cautela t√©cnica.\n\n" + resposta_final

        st.markdown(resposta_final + memoria_nota)
        st.session_state.messages.append({"role": "assistant", "content": resposta_final + memoria_nota})
        
        # Salvamento no DB
        supabase.table("historico_conversas").insert({
            "usuario": "Andr√©", "pergunta": prompt, "resposta": resposta_final, 
            "categoria": "importante" if (decisao.get("is_important") or uploaded_file) else "casual"
        }).execute()
